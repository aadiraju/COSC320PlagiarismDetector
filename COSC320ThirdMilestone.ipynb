{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COSC320ThirdMilestone.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadiraju/COSC320PlagiarismDetector/blob/main/COSC320ThirdMilestone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slUTMBmrWj41"
      },
      "source": [
        "# COSC320 Third Milestone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dPsAfRyVjEa"
      },
      "source": [
        "\n",
        "## Rabin-Karp Function \n",
        "The following cell defines a function that implements Rabin-Karp on the given pattern and text, and returns a plagiarism percentage from 0% - 100%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB74EmGY_9ow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b506988-ca0e-44da-a6b8-c9adeeada8f0"
      },
      "source": [
        "# Following program is the python implementation of \n",
        "# Rabin Karp Algorithm given in CLRS book \n",
        "  \n",
        "# pat  -> pattern \n",
        "# txt  -> text \n",
        "# q    -> A prime number \n",
        "  \n",
        "def rabinKarpSearch(pat, txt): \n",
        "    q = 101 # A prime number \n",
        "    M = len(pat) \n",
        "    N = len(txt) \n",
        "    i = 0\n",
        "    j = 0\n",
        "    p = 0    # hash value for pattern \n",
        "    t = 0    # hash value for txt \n",
        "    h = 1\n",
        "    # d is the number of characters in the input alphabet \n",
        "    d = 256\n",
        "  \n",
        "    # The value of h would be \"pow(d, M-1)% q\" \n",
        "    for i in range(M-1): \n",
        "        h = (h * d)% q \n",
        "  \n",
        "    # Calculate the hash value of pattern and first window \n",
        "    # of text \n",
        "    for i in range(M): \n",
        "        p = (d * p + ord(pat[i]))% q \n",
        "        t = (d * t + ord(txt[i]))% q \n",
        "  \n",
        "    # Slide the pattern over text one by one \n",
        "    for i in range(N-M + 1): \n",
        "        # Check the hash values of current window of text and \n",
        "        # pattern if the hash values match then only check \n",
        "        # for characters on by one \n",
        "        if p == t: \n",
        "            # Check for characters one by one \n",
        "            for j in range(M): \n",
        "                if txt[i + j] != pat[j]: \n",
        "                    break\n",
        "  \n",
        "            j+= 1\n",
        "            # if p == t and pat[0...M-1] = txt[i, i + 1, ...i + M-1] \n",
        "            if j == M: \n",
        "                return M #get length of pattern that has a match\n",
        "  \n",
        "        # Calculate hash value for next window of text: Remove \n",
        "        # leading digit, add trailing digit \n",
        "        if i < N-M: \n",
        "            t = (d*(t-ord(txt[i])*h) + ord(txt[i + M]))% q \n",
        "  \n",
        "            # We might get negative values of t, converting it to \n",
        "            # positive \n",
        "            if t < 0: \n",
        "                t = t + q\n",
        "    return 0\n",
        "\n",
        "def rabinKarpFileMatch(file, cFile):\n",
        "  corpusFileSize = len(cFile)\n",
        "  totalFoundChar = 0\n",
        "  for line in file:\n",
        "    totalFoundChar += rabinKarpSearch(line,cFile)\n",
        "  return float(totalFoundChar/corpusFileSize)*100 # value from 0-100 that represents the percentage of matches found between the two documents \n",
        "\n",
        "# Driver program to test the above function \n",
        "txt = \"COSC320 is a very fun class and I would take it again if I could\"\n",
        "pat = [\"very fun class \",\"aksdjfhaskjl \",\"take it again \"]\n",
        "\n",
        "print(\"{:.2f}% similarity\".format(rabinKarpFileMatch(pat, txt))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45.31% similarity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOxpWdjgWWL2"
      },
      "source": [
        "## KMP Function \n",
        "The following cell defines a function that implements KMP on the given pattern and text, and returns a plagiarism percentage from 0% - 100%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZusYoWoUBzNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f728c51f-fd19-4251-a4e9-28f42567be38"
      },
      "source": [
        "def kmpHelper(file,cFile):    \n",
        "    totalFoundChar = 0\n",
        "    for i in file:\n",
        "      totalFoundChar += KMPSearch(i,cFile)\n",
        "    \n",
        "    corpusFileSize = len(cFile)\n",
        "    return float(totalFoundChar/corpusFileSize)*100\n",
        "    \n",
        "    # for each string in data, run a for loop to check against each string in the data2 string, so that can be done, and then to return a \n",
        "\n",
        "\n",
        "def KMPSearch(pat, txt): \n",
        "    M = len(pat) \n",
        "    N = len(txt) \n",
        "    lps = [0]*M \n",
        "    j = 0\n",
        "    computeLPSArray(pat, M, lps) \n",
        "    i = 0 \n",
        "    while i < N: \n",
        "        if pat[j] == txt[i]: \n",
        "            i += 1\n",
        "            j += 1\n",
        "        if j == M: \n",
        "            return M\n",
        "            j = lps[j-1] \n",
        "\n",
        "        elif i < N and pat[j] != txt[i]: \n",
        "            if j != 0: \n",
        "                j = lps[j-1] \n",
        "            else: \n",
        "                i += 1\n",
        "    return 0\n",
        "  \n",
        "def computeLPSArray(pat, M, lps): \n",
        "    len = 0 # length of the previous longest prefix suffix \n",
        "  \n",
        "    lps[0] # lps[0] is always 0 \n",
        "    i = 1\n",
        "  \n",
        "    # the loop calculates lps[i] for i = 1 to M-1 \n",
        "    while i < M: \n",
        "        if pat[i]== pat[len]: \n",
        "            len += 1\n",
        "            lps[i] = len\n",
        "            i += 1\n",
        "        else: \n",
        "            # This is tricky. Consider the example. \n",
        "            # AAACAAAA and i = 7. The idea is similar  \n",
        "            # to search step. \n",
        "            if len != 0: \n",
        "                len = lps[len-1] \n",
        "  \n",
        "                # Also, note that we do not increment i here \n",
        "            else: \n",
        "                lps[i] = 0\n",
        "                i += 1\n",
        "  \n",
        "txt = \"ABABDABACDABABCABABABCABCBABCABCBACBACBACBACBABCBACBABD\"\n",
        "pat = [\"CAB\",\"BAB\"]\n",
        "print(\"{:.2f}% similarity\".format(kmpHelper(pat, txt))) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.91% similarity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg5ZYoc4Wpyd"
      },
      "source": [
        "## LCSS Function \n",
        "The following cell defines a function that implements LCSS on the given pattern and text, and returns a plagiarism percentage from 0% - 100%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCh9q7E6UV9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce50a688-e8f1-4d0b-d3d5-87f7e3e672c5"
      },
      "source": [
        "def lcs(file, cFile): \n",
        "    # find the length of the strings \n",
        "    m = len(file) \n",
        "    n = len(cFile) \n",
        "  \n",
        "    # declaring the array for storing the dp values \n",
        "    L = [[None]*(n + 1) for i in range(m + 1)] \n",
        "  \n",
        "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion \n",
        "    Note: L[i][j] contains length of LCS of file[0..i-1] \n",
        "    and cFile[0..j-1]\"\"\"\n",
        "    for i in range(m + 1): \n",
        "        for j in range(n + 1): \n",
        "            if i == 0 or j == 0 : \n",
        "                L[i][j] = 0\n",
        "            elif file[i-1] == cFile[j-1]: \n",
        "                L[i][j] = L[i-1][j-1]+1\n",
        "            else: \n",
        "                L[i][j] = max(L[i-1][j], L[i][j-1]) \n",
        "  \n",
        "    # L[m][n] contains the length of LCS of file[0..n-1] & cFile[0..m-1] \n",
        "    return L[m][n] \n",
        "# end of function lcs \n",
        "def lcsHelper(file,cFile):\n",
        "  totalFoundChar = 0\n",
        "  for i in file:\n",
        "    totalFoundChar += lcs(i,cFile)  \n",
        "  corpusFileSize = len(cFile)\n",
        "  return float(totalFoundChar/corpusFileSize)*100\n",
        "  \n",
        "# Driver program to test the above function \n",
        "file = [\"AGG\"]\n",
        "cFile = \"GXTXAYB\"\n",
        "print(\"Similarity Percentage is {:.2f}%\".format(lcsHelper(file, cFile))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity Percentage is 14.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_bJe5gjXY6f"
      },
      "source": [
        "## Main Driver Function\n",
        "The following function will take the actual input file and compare it against each file in the corpus and return a plagiarism percentage per file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZprO9t2h33p-"
      },
      "source": [
        "def plagDetect(directory, dirSize, plagThresh, plagTestFile):\n",
        "    '''\n",
        "    Function that will return a set of filenames from which plagTestFile might have plagiarized from.\n",
        "\n",
        "    Parameters:\n",
        "    directory : str - path to directory where data files are located\n",
        "    dirSize : int - number of files other than plagTestFile that the algorithm will search from\n",
        "    plagThresh : float - a floating-point number between 0 - 1, that defines the percentage threshold to classify a document as potentially plagiarized\n",
        "    plagTestFile : str - name of the plagiarism test file with extension. No directory. Eg: \"plagTestFile.txt\"\n",
        "\n",
        "    Returns:\n",
        "    potentialPlagDocSet : list(str) - list of filenames in directory from which plagTestFile has plagiarized from.\n",
        "\n",
        "    '''\n",
        "    corpus = []\n",
        "    corpusNames = []\n",
        "    plagF = \"\"\n",
        "    counter = 0\n",
        "\n",
        "    for file in os.listdir(directory):\n",
        "         filename = os.fsdecode(file)\n",
        "         if filename.endswith(\".txt\") and filename != plagTestFile and counter < dirSize: \n",
        "             #Take in each corpus file as a big string where newlines are replaced by spaces\n",
        "             cf = open(os.path.join(directory,file), \"r\", encoding=\"utf-8\")\n",
        "             content = cf.read()\n",
        "             content_list = content.replace('\\n',' ')\n",
        "             corpus.append(content_list)\n",
        "             corpusNames.append(filename)\n",
        "             counter+=1\n",
        "             cf.close()  \n",
        "         if filename == plagTestFile:\n",
        "            # For the plagirarism file, split up by line, in a list.\n",
        "            with open(os.path.join(directory,file),'r', encoding=\"utf-8\") as plagFile:\n",
        "                plagF = [line.rstrip('\\n') for line in plagFile]\n",
        "    \n",
        "    potentialPlagDocSet = []\n",
        "\n",
        "    for i in range(len(corpus)):\n",
        "        cFile = corpus[i]\n",
        "        cFileName = corpusNames[i]\n",
        "        simil = 0.5 * kmpHelper(plagF, cFile) + 0.2 * rabinKarpFileMatch(plagF, cFile) + 0.3 * lcsHelper(plagF, cFile)\n",
        "        if simil > plagThresh:\n",
        "            potentialPlagDocSet.append(cFileName)\n",
        "            \n",
        "    return potentialPlagDocSet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icXts3C45nhW"
      },
      "source": [
        "## Runtime Plotting\n",
        "The following code blocks will run our function a bunch of times with varying corpus sizes, and record and plot the run time using `matplotlib`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyRZRWselwwG"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from random import choice\n",
        "import os\n",
        "\n",
        "def tryItABunch(myFn, startN=1, endN=100, stepSize=1, numTrials=20):\n",
        "    nValues = []\n",
        "    tValues = []\n",
        "    directory = \"g17_corpusfinal/\"\n",
        "    plagThresh = 0.1\n",
        "    plagTestFile = \"plagarism_test_file.txt\"\n",
        "    for n in range(startN, endN, stepSize):\n",
        "        # run myFn several times and average to get a decent idea.\n",
        "        runtime = 0\n",
        "        for t in range(numTrials):\n",
        "            lst = n # generate a random list of length n\n",
        "            start = time.time()\n",
        "            myFn(directory, n, plagThresh, plagTestFile)\n",
        "            end = time.time()\n",
        "            runtime += (end - start) * 1000 # measure in milliseconds\n",
        "        runtime = runtime/numTrials\n",
        "        nValues.append(n)\n",
        "        tValues.append(runtime)\n",
        "\n",
        "    return nValues, tValues\n",
        "\n",
        "\n",
        "start = 1\n",
        "end = 100\n",
        "step = 10\n",
        "nFiles, tTimesofRuntime = tryItABunch( plagDetect, startN = start, endN = end, stepSize=step, numTrials=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3znP0uHS-Vfy"
      },
      "source": [
        "tTimesofRuntime = [x/1000 for x in tTimesofRuntime]\n",
        "\n",
        "tValues = [ x for x in range(start,end,step)]\n",
        "nValues = [ x for x in range(start,end,step)]\n",
        "\n",
        "plt.plot(nFiles, tTimesofRuntime, color=\"red\", label=\"Actual Runtime\")\n",
        "plt.plot(nValues, tValues, color=\"blue\", label=\"Theoretical Runtime\")\n",
        "plt.xlabel(\"n\")\n",
        "plt.ylabel(\"Time(s)\")\n",
        "plt.legend()\n",
        "plt.title(\"Naive algorithm theoretical runtime vs. actual runtime\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}